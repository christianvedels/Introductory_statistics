<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Slides.knit</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.30/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="libs/panelset-0.3.0/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.3.0/panelset.js"></script>
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/xaringanExtra-progressBar-0.0.1/progress-bar.js"></script>
  </head>
  <body>
    <textarea id="source">

class: center, inverse, middle





<style>.xe__progress-bar__container {
  top:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #808080;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>

&lt;style type="text/css"&gt;
.pull-left {
  float: left;
  width: 44%;
}
.pull-right {
  float: right;
  width: 44%;
}
.pull-right ~ p {
  clear: both;
}


.pull-left-wide {
  float: left;
  width: 66%;
}
.pull-right-wide {
  float: right;
  width: 66%;
}
.pull-right-wide ~ p {
  clear: both;
}

.pull-left-narrow {
  float: left;
  width: 30%;
}
.pull-right-narrow {
  float: right;
  width: 30%;
}

.tiny123 {
  font-size: 0.40em;
}

.small123 {
  font-size: 0.80em;
}

.large123 {
  font-size: 2em;
}

.red {
  color: red
}

.orange {
  color: orange
}

.green {
  color: green
}
&lt;/style&gt;



# Statistics
## Random variables
### (Chapter 4)

### Seetha Menon,&lt;br&gt;Department of Economics&lt;br&gt;University of Southern Denmark

### Email: [smr@sam.sdu.dk](mailto:smr@sam.sdu.dk)

### Updated 2026-02-12



---
class: inverse, middle, center
# Definition of a random variable

---
# Random variable

--

&gt; A **random variable** is a *function* that assigns a numerical value to any outcome of an experiment.

--

- Examples:
  - in the experiment of tossing a coin, we could have:
`$$X(\text{"heads"}) = 0, \quad X(\text{"tails"}) = 1$$`
  - in the experiment of rolling a dice, we could have:
`$$X(1) = 1, \; X(2) = 2, \; X(3) = 3, \; X(4) = 4, \; X(5) = 5, \; X(6) = 6$$`

---
# Random variable

--

- As a general rule, we use letters at the end of the alphabet:
  - uppercase to denote random variables (e.g., `\(X\)`, `\(Y\)`)
  - lowercase for the specific values a random variable can take (e.g., `\(x\)`, `\(y\)`)

--

- Note that we can choose the values assigned to the various outcomes, but sometimes certain values may be more suited to the problem at hand

--

- For example, suppose that the experiment is "choose a person at random, ask her age"
  - outcomes: values of "age of the person" (say, 43 years)
  - random variable: assign a number to the outcome "age of person = 43 years"
  - "natural" value: 43

---
# Types of random variables

--

- There are two types of random variables based on the number of values they can take:

--

  - **discrete random variables** can take a *countable* (finite or infinite) number of values
    - examples: toss of a coin, roll of a dice, pick an integer
    - if an experiment has a finite number of outcomes, then the corresponding random variable is *usually* discrete

--

  - **continuous random variables** take an *uncountable* number of values
    - examples: exact quantity of rainfall over a year, exact profit corresponding to a share (profit divided by number of shares)
    - note that the same experiment can produce a discrete or a continuous random variable, depending on how "accurately" the outcome is measured


---
class: inverse, middle, center
# Discrete random variables

---
# Probability function

--

- One advantage of using random variables is that now we work with numbers instead of abstract events

--

- So, we can use mathematical concepts built for numbers, such as functions

--

&gt; The **probability function** `\(f(\cdot)\)` of a discrete random variable `\(X\)` is defined as:
&gt; `$$f(x) = P(X = x)$$`

--

- When working with several random variables, say `\(X\)` and `\(Y\)`, it is sometimes useful to distinguish their probability functions by indexing them: `\(f_X(x)\)` and `\(f_Y(y)\)`

---
# Probability function

--

- Examples:
  - in the experiment of tossing a coin, we would have:
`$$f(0) = P(X = 0) = P(\text{"heads"}) = \frac{1}{2}$$`
`$$f(1) = P(X = 1) = P(\text{"tails"}) = \frac{1}{2}$$`

--

&gt; **Properties of the probability function:**
&gt;
&gt; (i) `\(0 \leq f(x) \leq 1\)` for all `\(x\)`
&gt;
&gt; (ii) `\(\displaystyle\sum_{i=1}^N f(x_i) = f(x_1) + f(x_2) + \ldots + f(x_N) = 1\)`, where `\(x_1, x_2, \ldots, x_N\)` are the possible values of `\(X\)`

---
# Cumulative distribution function

--

&gt; The **cumulative distribution function** `\(F(\cdot)\)` of a discrete random variable `\(X\)` is defined as:
&gt; `$$F(x) = P(X \leq x) = \sum_{x_i \leq x} f(x_i)$$`

--

- Note that, by construction, the cumulative distribution is an *increasing* function

--

- Example:
  - in the experiment of rolling a dice, we would have:
`$$f(4) = P(X = 4) = P(\text{"dice shows 4"}) = \frac{1}{6}$$`
`$$F(4) = P(X \leq 4) = P(\text{"dice shows at most 4"})$$`
`$$= P(X = 1) + P(X = 2) + P(X = 3) + P(X = 4) = \frac{4}{6}$$`

---
# Cumulative distribution function

.center[
![Discrete CDF](Figures/4. Discrete CDF.png)
]

---
# Cumulative distribution function

--

- The cumulative distribution function also allows us to calculate the probability that `\(X\)` will take on a value in a given range:

--

`$$P(a &lt; X \leq b) = F(b) - F(a)$$`

--

and:

`$$P(a \leq X \leq b) = F(b) - F(a) + f(a)$$`

---
# Probability functions and relative frequencies

--

- Suppose the frequency of a particular outcome `\(z\)` in the population is given by the function `\(g(z)\)` (e.g., in an urn including 3 red balls and 5 blue balls, red balls have a relative frequency of "3 in 8" and blue balls of "5 in 8")

--

- Let `\(Z\)` be a random variable whose values indicate the outcome in this population (i.e., the color of the ball)

--

- If all elements in the population have an equal chance of being selected, then the probability function of `\(Z\)` is:
`$$f(z) = g(z)$$`

--

- In our example, if `\(Z = 1\)` indicates "red ball" and `\(Z = 2\)` indicates "blue ball," then:
`$$f(1) = \frac{3}{8} \qquad f(2) = \frac{5}{8}$$`


---
class: inverse, middle, center
# Relationships between discrete random variables

---
# Relationships between random variables

--

- Sometimes, we are interested in studying the relationship between two types of events

--

- For example, suppose that a bank wants to assess the risk of bankruptcy of a company asking for a loan

--

- The bank knows that this will depend on the state of the economy: booming or in recession

--

- Hence, the bank would like to know how risky the loan is as a function of:
  - how likely the company is to go bankrupt
  - how likely the economy is to be in recession

---
# Joint probability

--

&gt; The **joint probability function** `\(f(\cdot, \cdot)\)` for two discrete random variables `\(X\)` and `\(Y\)` is defined as:
&gt; `$$f(x, y) = P(X = x \text{ and } Y = y)$$`

--

- Example:

| | `\(X = 0\)` (bankrupt) | `\(X = 1\)` (not bankrupt) |
|---|:---:|:---:|
| `\(Y = 0\)` (recession) | 0.2 | 0.2 |
| `\(Y = 1\)` (boom) | 0.1 | 0.5 |

---
# Joint probability

--

&gt; **Properties of the joint probability function:**
&gt;
&gt; 1. `\(0 \leq f(x, y) \leq 1\)` for all `\(x, y\)`
&gt;
&gt; 2. `\(\displaystyle \sum_{i=1}^{N_x} \sum_{j=1}^{N_y} f(x_i, y_j) = f(x_1, y_1) + f(x_1, y_2) + \ldots + f(x_{N_x}, y_{N_y}) = 1\)`
&gt;
&gt; where `\(x_1, x_2, \ldots, x_{N_x}\)` are all the possible values of `\(X\)`, and `\(y_1, y_2, \ldots, y_{N_y}\)` are all the possible values of `\(Y\)`

--

- In our example, what we need (for the second property) is:
`$$0.2 + 0.2 + 0.1 + 0.5 = 1$$`

---
# Marginal probability

--

&gt; The **marginal probability function** `\(f_X(\cdot)\)` of a discrete random variable `\(X\)` is defined as:
&gt; `$$f_X(x) = \sum_{j=1}^{N_y} f(x, y_j) = f(x, y_1) + f(x, y_2) + \ldots + f(x, y_{N_y})$$`

---
# Marginal probability

--

- In other words, the marginal probability function of `\(X\)` is the column sum of probabilities (and the marginal probability function of `\(Y\)` is the row sum):

| | `\(X = 0\)` (bankrupt) | `\(X = 1\)` (not bankrupt) | `\(f_Y(\cdot)\)` |
|---|:---:|:---:|:---:|
| `\(Y = 0\)` (recession) | 0.2 | 0.2 | 0.4 |
| `\(Y = 1\)` (boom) | 0.1 | 0.5 | 0.6 |
| `\(f_X(\cdot)\)` | 0.3 | 0.7 | |

---
# Conditional probability

--

- Recall the definition of the conditional probability:
`$$P(A | B) = \frac{P(A \cap B)}{P(B)}$$`

--

- Now suppose that the event `\(A\)` is represented by `\(X = x\)` and the event `\(B\)` by `\(Y = y\)`

--

- We can then write the conditional probability as:
`$$P(X = x | Y = y) = \frac{P(X = x \text{ and } Y = y)}{P(Y = y)}$$`

--

- But note that, by definition:
  - the numerator is the joint probability function `\(f(x, y)\)`
  - the denominator is the marginal probability function `\(f_Y(y)\)`

---
# Conditional probability

--

&gt; The **conditional probability function** `\(f_{X|Y}(\cdot, \cdot)\)` of a discrete random variable `\(X\)` given that `\(Y = y\)` is defined as:
&gt; `$$f_{X|Y}(x | y) = \frac{f(x, y)}{f_Y(y)}$$`
&gt; if `\(f_Y(y) &gt; 0\)`

--

- Example:
  - what is the probability of bankruptcy ( `\(X = 0\)` ) given that we know we are in a boom ( `\(Y = 1\)` )?
`$$f_{X|Y}(0 | 1) = \frac{f(0, 1)}{f_Y(1)} = \frac{0.1}{0.6} = 0.167 = 16.7\%$$`

---
# Bayes' theorem

--

- In practice, sometimes we know the conditional probability of `\(X\)` given `\(Y\)`, but we are interested in the conditional probability of `\(Y\)` given `\(X\)`

--

- For example, you may know from a car dealer friend of yours what is the probability of a "lemon" (bad car) having a low price, but you would want to know what is the probability that a cheap car is a lemon

--

- We can use the definition of the conditional probability to write:
`$$f_{Y|X}(y | x) = \frac{f(x, y)}{f_X(x)}$$`

--

- From here it is easy to prove the following theorem

---
# Bayes' theorem

--

&gt; **Bayes' theorem:**
&gt;
&gt; 1. `\(f_{X|Y}(x | y) = f_{Y|X}(y | x) \cdot \displaystyle\frac{f_X(x)}{f_Y(y)}\)`
&gt;
&gt; 2. `\(f_{X|Y}(x | y) = f_{Y|X}(y | x) \cdot \displaystyle\frac{f_X(x)}{\displaystyle\sum_{i=1}^{N_x} \left\{ f_{Y|X}(y | x_i) \cdot f_X(x_i)\right\}}\)`

---
# Bayes' theorem: Example

--

- Let `\(X\)` be the random variable indicating whether the car is a lemon ( `\(X = 1\)` ) or not ( `\(X = 0\)` )

--

- Let `\(Y\)` be the random variable indicating whether the price is low ( `\(Y = 1\)` ) or not ( `\(Y = 0\)` )

--

- From your car dealer friend, you know that there is a 75% probability of a low price if the car is a lemon and a 20% probability of a low price if the car is not a lemon

--

- This gives you the conditional probability function of `\(Y\)` given `\(X\)`:
`$$f_{Y|X}(1 | 1) = 0.75, \quad f_{Y|X}(0 | 1) = 0.25$$`
`$$f_{Y|X}(1 | 0) = 0.20, \quad f_{Y|X}(0 | 0) = 0.80$$`

--

- From technical reports, you also know that 25% of the cars on the market are lemons, which gives you the marginal probability function of `\(X\)`:
`$$f_X(1) = 0.25 \quad f_X(0) = 0.75$$`

---
# Bayes' theorem: Example

--

- From here you only need to apply Bayes' theorem to find the conditional probability of a lemon given that the price is low:

`$$f_{X|Y}(1 | 1) = f_{Y|X}(1 | 1) \cdot \frac{f_X(1)}{\displaystyle\sum_{i=1}^{N_x} \left\{ f_{Y|X}(1 | x_i) \cdot f_X(x_i)\right\}}$$`

--

`$$= f_{Y|X}(1 | 1) \cdot \frac{f_X(1)}{f_{Y|X}(1 | 0) \cdot f_X(0) + f_{Y|X}(1 | 1) \cdot f_X(1)}$$`

--

`$$= 0.75 \cdot \frac{0.25}{0.20 \cdot 0.75 + 0.75 \cdot 0.25} = 0.556$$`

--

- Therefore, there is a 55.6% chance that a car is a lemon if it has a low price

---
# Independence

--

- Recall the definition of independence between two events `\(A\)` and `\(B\)`:
`$$P(A \cap B) = P(A) \cdot P(B)$$`

--

- Now suppose that the event `\(A\)` is represented by `\(X = x\)` and the event `\(B\)` by `\(Y = y\)`

--

- We can then write the independence condition as:
`$$P(X = x \text{ and } Y = y) = P(X = x) \cdot P(Y = y)$$`

--

- But note that, by definition:
  - the left hand side is the joint probability function `\(f(x, y)\)`
  - the right hand side is the product of marginal probability functions `\(f_X(x)\)` and `\(f_Y(y)\)`

---
# Independence

--

&gt; Two discrete random variables `\(X\)` and `\(Y\)` are **independent** if and only if:
&gt; `$$f(x, y) = f_X(x) \cdot f_Y(y)$$`
&gt; for all `\(x\)` and `\(y\)`. This implies that:
&gt;
&gt; 1. `\(f_{X|Y}(x | y) = f_X(x)\)` for all values `\(y\)` such that `\(f_Y(y) &gt; 0\)`
&gt;
&gt; 2. `\(f_{Y|X}(y | x) = f_Y(y)\)` for all values `\(x\)` such that `\(f_X(x) &gt; 0\)`

--

- Examples: tossing a coin twice, rolling a dice twice


---
class: inverse, middle, center
# Continuous random variables

---
# Continuous random variables

--

- Imagine that your company wants to predict its output next year

--

- It knows that it will produce between 10 and 20 tons of concrete, but it can be *any* number between 10 and 20 (with equal probability)

--

- What is the probability that it will produce *exactly* 15 tons? Basically zero
  - if it produces 14.999999 or 15.000001, this is not exactly 15
  - it would be extremely hard to get to exactly 15 tons

--

- Using the same argument, the probability of producing *exactly* any particular quantity is zero `\(\Rightarrow\)` the concept of probability function does not make sense

--

- Since continuous random variables have an uncountable number of values, we cannot use the exact same concepts as in the case of discrete random variables

--

- However, we only need to make minor changes to them in order to generalize them to this type of variables

---
# Cumulative distribution function

--

&gt; The **cumulative distribution function** `\(F(\cdot)\)` of a continuous random variable `\(X\)` is defined as:
&gt; `$$F(x) = P(X \leq x)$$`

--

- This is the same definition as in the case of a discrete random variable

--

- However, note that in this case it does not make a difference if the inequality is strict or not:
`$$P(X \leq x) = P(X &lt; x \text{ or } X = x) = P(X &lt; x) + P(X = x) = P(X &lt; x)$$`
because `\(P(X = x) = 0\)`

---
# Cumulative distribution function

.center[
![Continuous CDF](Figures/4. Continuous CDF.png)
]

---
# Probability density function

--

&gt; The **probability density function** `\(f(\cdot)\)` of a continuous random variable `\(X\)` is defined as:
&gt; `$$f(x) = \frac{dF(x)}{dx}$$`

--

- This definition has several implications:

--

  - the area under the probability density function is always equal to one:
`$$\int_{-\infty}^\infty f(x) \, dx = 1$$`

--

  - the cumulative distribution function is the integral of the probability density function:
`$$F(x) = \int_{-\infty}^x f(z) \, dz$$`

---
# Example

--

- In our example, the likelihood of any value between 10 and 20 is the same

--

- In other words, the value of the density function is the same for all values of `\(X\)`:
`$$f(x) = c$$`

--

- We can then use the properties of the probability density function to calculate the exact value of `\(c\)`:
`$$\int_{-\infty}^\infty f(x) \, dx = \int_{10}^{20} c \, dx = (20 - 10) c = 1 \; \Rightarrow \; c = 0.1$$`

--

- We can now calculate the cumulative distribution function:
`$$F(x) = \int_{-\infty}^x f(z) \, dz = \int_{10}^x 0.1 \, dz = 0.1 (x - 10)$$`
for all `\(z\)` such that `\(10 \leq z \leq 20\)`

---
# Example

--

- Now we can write explicitly the probability density function:
`$$f(x) = \begin{cases} 0, &amp; \text{if } x &lt; 10 \\ 0.1, &amp; \text{if } 10 \leq x \leq 20 \\ 0, &amp; \text{if } x &gt; 20 \end{cases}$$`

--

- The cumulative distribution function is:
`$$F(x) = \begin{cases} 0, &amp; \text{if } x &lt; 10 \\ 0.1(x - 10), &amp; \text{if } 10 \leq x \leq 20 \\ 1, &amp; \text{if } x &gt; 20 \end{cases}$$`

---
# Probability density function

.center[
![Continuous PDF](Figures/4. Continuous PDF.png)
]

---
# Probability density and cumulative distribution functions

.center[
![Continuous PDF total area](Figures/4. Continuous PDF total area.png)
]

---
# Probability density and cumulative distribution functions

.center[
![Continuous PDF partial area](Figures/4. Continuous PDF partial area.png)
]


---
class: inverse, middle, center
# Relationships between continuous random variables

---
# Joint probability density

--

- We can use the same notions defined in the case of discrete random variables, but replacing the probability function with the probability density function and summations with integrals

--

&gt; The **joint probability density function** `\(f(\cdot, \cdot)\)` for two continuous random variables `\(X\)` and `\(Y\)` is written as `\(f(x, y)\)`.

--

- Since this is a probability density function, the area under it must "sum up" to one:
`$$\int_{-\infty}^\infty \int_{-\infty}^\infty f(x, y) \, dx \, dy = 1$$`

---
# Marginal probability density

--

&gt; The **marginal probability density function** `\(f_X(\cdot)\)` of a continuous random variable `\(X\)` is defined as:
&gt; `$$f_X(x) = \int_{-\infty}^\infty f(x, y) \, dy$$`

--

- Since this is a probability density function, the area under it must "sum up" to one:
`$$\int_{-\infty}^\infty f_X(x) \, dx = 1$$`

---
# Conditional probability density

--

&gt; The **conditional probability density function** `\(f_{X|Y}(x|y)\)` of a continuous random variable `\(X\)` given that `\(Y = y\)` is defined as:
&gt; `$$f_{X|Y}(x | y) = \frac{f(x, y)}{f_Y(y)} \text{ if } f_Y(y) &gt; 0.$$`

--

- Again, the area under this function must "sum up" to one because it is a probability density function:
`$$\int_{-\infty}^\infty f_{X|Y}(x | y) \, dx = 1$$`
for all `\(y\)` such that `\(f_Y(y) &gt; 0\)`

---
# Bayes' theorem

--

- Bayes' theorem applies to the continuous case in a similar way to the discrete case

--

&gt; **Bayes' theorem:**
&gt;
&gt; 1. `\(f_{X|Y}(x | y) = f_{Y|X}(y | x) \cdot \displaystyle\frac{f_X(x)}{f_Y(y)}\)`
&gt;
&gt; 2. `\(f_{X|Y}(x | y) = f_{Y|X}(y | x) \cdot \displaystyle\frac{f_X(x)}{\displaystyle\int_{-\infty}^{\infty} f_{Y|X}(y | z) f_X(z) \, dz}\)`

---
# Independence

--

- Finally, the concept of independence is similar in the continuous case to the discrete case

--

&gt; Two continuous random variables `\(X\)` and `\(Y\)` are **independent** if and only if:
&gt; `$$f(x, y) = f_X(x) \cdot f_Y(y)$$`
&gt; for all `\(x\)` and `\(y\)`. This implies that:
&gt;
&gt; 1. `\(f_{X|Y}(x | y) = f_X(x)\)` for all values `\(y\)` such that `\(f_Y(y) &gt; 0\)`
&gt;
&gt; 2. `\(f_{Y|X}(y | x) = f_Y(y)\)` for all values `\(x\)` such that `\(f_X(x) &gt; 0\)`

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "highlightStyle": "github",
  "highlightLines": true,
  "countIncrementalSlides": false,
  "ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url(SDU_logo.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 125px;
  height: 60px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // insert more to hide here
    ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
